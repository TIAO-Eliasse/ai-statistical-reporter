"""
Week 2 - Architect Agent
Agent pour analyser les donnÃ©es CSV et gÃ©nÃ©rer un plan de rapport

VERSION AMÃ‰LIORÃ‰E avec :
- Support des profils de rÃ©daction (AcadÃ©mique, Consultant, Institutionnel)
- Gestion encodage CSV/Excel (UTF-8, Latin-1, ISO-8859-1, Windows-1252)
- Support Excel (.xlsx, .xls)
- Adaptation du plan selon le profil
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, Optional, Union


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORT DES PROFILS (si disponibles)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    from study_context import WritingProfile
    from writing_profiles import get_profile_summary
    PROFILES_AVAILABLE = True
except ImportError:
    PROFILES_AVAILABLE = False
    # DÃ©finir des profils simples en fallback
    class WritingProfile:
        ACADEMIC = "academic"
        CONSULTANT = "consultant"
        INSTITUTIONAL = "institutional"


def analyze_csv(csv_path: str) -> Dict[str, Any]:
    """
    Analyse un fichier CSV/Excel et retourne les mÃ©tadonnÃ©es
    
    Args:
        csv_path: Chemin vers le fichier CSV ou Excel
        
    Returns:
        Dict contenant les mÃ©tadonnÃ©es du fichier
    """
    
    # VÃ©rifier si E2B est disponible
    try:
        from e2b_code_interpreter import Sandbox
        USE_E2B = True
    except ImportError:
        USE_E2B = False
    
    if USE_E2B:
        return _analyze_csv_with_e2b(csv_path)
    else:
        return _analyze_csv_locally(csv_path)


def _analyze_csv_locally(csv_path: str) -> Dict[str, Any]:
    """Analyse le CSV localement (fallback si E2B non disponible)"""
    import pandas as pd
    import numpy as np
    
    file_path = Path(csv_path)
    file_extension = file_path.suffix.lower()
    
    # Chargement avec gestion encodage
    if file_extension == '.csv':
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            encoding_used = 'utf-8'
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file_path, encoding='latin-1')
                encoding_used = 'latin-1'
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(file_path, encoding='iso-8859-1')
                    encoding_used = 'iso-8859-1'
                except UnicodeDecodeError:
                    df = pd.read_csv(file_path, encoding='windows-1252')
                    encoding_used = 'windows-1252'
    
    elif file_extension in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path, engine='openpyxl' if file_extension == '.xlsx' else None)
        encoding_used = 'excel'
    
    else:
        raise ValueError(f"Format de fichier non supportÃ© : {file_extension}")
    
    # Collecter les mÃ©tadonnÃ©es
    metadata = {
        "file_info": {
            "filename": file_path.name,
            "extension": file_extension,
            "encoding": encoding_used
        },
        "shape": {
            "rows": int(df.shape[0]),
            "columns": int(df.shape[1])
        },
        "columns": list(df.columns),
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "numeric_columns": list(df.select_dtypes(include=['number']).columns),
        "categorical_columns": list(df.select_dtypes(include=['object', 'category']).columns),
        "missing_values": {},
        "basic_stats": {}
    }
    
    # Valeurs manquantes
    for col in df.columns:
        missing_count = df[col].isnull().sum()
        metadata["missing_values"][col] = {
            "count": int(missing_count),
            "percentage": round((missing_count / len(df)) * 100, 2)
        }
    
    # Statistiques numÃ©riques
    for col in metadata["numeric_columns"]:
        try:
            col_data = df[col].dropna()
            if len(col_data) > 0:
                metadata["basic_stats"][col] = {
                    "count": int(len(col_data)),
                    "mean": float(col_data.mean()),
                    "median": float(col_data.median()),
                    "std": float(col_data.std()),
                    "min": float(col_data.min()),
                    "max": float(col_data.max()),
                    "q25": float(col_data.quantile(0.25)),
                    "q75": float(col_data.quantile(0.75))
                }
        except Exception as e:
            print(f"Warning: Could not compute stats for {col}: {e}")
    
    # Statistiques catÃ©gorielles
    for col in metadata["categorical_columns"]:
        try:
            value_counts = df[col].value_counts()
            metadata["basic_stats"][col] = {
                "unique_count": int(df[col].nunique()),
                "most_common": {str(k): int(v) for k, v in value_counts.head(10).items()}
            }
        except Exception as e:
            print(f"Warning: Could not compute stats for {col}: {e}")
    
    return metadata


def _analyze_csv_with_e2b(csv_path: str) -> Dict[str, Any]:
    """Analyse le CSV en utilisant E2B (sandbox isolÃ©)"""
    from e2b_code_interpreter import Sandbox
    
    with open(csv_path, 'rb') as f:
        file_content = f.read()
    
    file_path = Path(csv_path)
    file_extension = file_path.suffix.lower()
    
    python_code = f"""
import pandas as pd
import numpy as np
import json

def load_data_file(filepath):
    from pathlib import Path
    
    file_path = Path(filepath)
    file_extension = file_path.suffix.lower()
    
    if file_extension == '.csv':
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252', 'cp1252']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(filepath, encoding=encoding)
                return df, encoding
            except (UnicodeDecodeError, Exception):
                continue
        
        raise ValueError("Impossible de dÃ©tecter l'encodage du fichier CSV")
    
    elif file_extension in ['.xlsx', '.xls']:
        try:
            df = pd.read_excel(filepath, engine='openpyxl' if file_extension == '.xlsx' else None)
            return df, 'excel'
        except ImportError:
            raise ImportError("openpyxl ou xlrd non installÃ© pour lire Excel")
    
    else:
        raise ValueError(f"Format de fichier non supportÃ© : {{file_extension}}")

df, encoding_used = load_data_file('/home/user/data{file_extension}')

metadata = {{
    "file_info": {{
        "filename": "{file_path.name}",
        "extension": "{file_extension}",
        "encoding": encoding_used
    }},
    "shape": {{
        "rows": int(df.shape[0]),
        "columns": int(df.shape[1])
    }},
    "columns": list(df.columns),
    "dtypes": {{col: str(dtype) for col, dtype in df.dtypes.items()}},
    "numeric_columns": list(df.select_dtypes(include=['number']).columns),
    "categorical_columns": list(df.select_dtypes(include=['object', 'category']).columns),
    "missing_values": {{}},
    "basic_stats": {{}}
}}

for col in df.columns:
    missing_count = df[col].isnull().sum()
    metadata["missing_values"][col] = {{
        "count": int(missing_count),
        "percentage": round((missing_count / len(df)) * 100, 2)
    }}

for col in metadata["numeric_columns"]:
    try:
        col_data = df[col].dropna()
        if len(col_data) > 0:
            metadata["basic_stats"][col] = {{
                "count": int(len(col_data)),
                "mean": float(col_data.mean()),
                "median": float(col_data.median()),
                "std": float(col_data.std()),
                "min": float(col_data.min()),
                "max": float(col_data.max()),
                "q25": float(col_data.quantile(0.25)),
                "q75": float(col_data.quantile(0.75))
            }}
    except Exception as e:
        pass

for col in metadata["categorical_columns"]:
    try:
        value_counts = df[col].value_counts()
        metadata["basic_stats"][col] = {{
            "unique_count": int(df[col].nunique()),
            "most_common": {{str(k): int(v) for k, v in value_counts.head(10).items()}}
        }}
    except Exception as e:
        pass

print(json.dumps(metadata))
"""
    
    try:
        sandbox = Sandbox()
        sandbox.files.write(f'/home/user/data{file_extension}', file_content)
        execution = sandbox.run_code(python_code)
        
        if execution.error:
            raise Exception(f"Erreur lors de l'analyse: {execution.error}")
        
        output = execution.logs.stdout[0] if execution.logs.stdout else "{}"
        metadata = json.loads(output)
        
        sandbox.close()
        
        return metadata
    
    except Exception as e:
        print(f"E2B error, falling back to local analysis: {e}")
        return _analyze_csv_locally(csv_path)


def generate_report_plan(
    metadata: Dict[str, Any],
    study_context: Optional[Any] = None,
    writing_profile: Optional[Union[str, 'WritingProfile']] = None
) -> Dict[str, Any]:
    """
    GÃ©nÃ¨re un plan de rapport basÃ© sur les mÃ©tadonnÃ©es
    
    Args:
        metadata: MÃ©tadonnÃ©es du fichier CSV
        study_context: Contexte de l'Ã©tude (optionnel)
        writing_profile: Profil de rÃ©daction (academic/consultant/institutional)
        
    Returns:
        Dict contenant le plan du rapport
    """
    import google.generativeai as genai
    from datetime import datetime
    
    # Configuration de Gemini
    api_key = os.getenv("GMINI_API_KEY")
    
    if not api_key:
        raise ValueError("GMINI_API_KEY non trouvÃ©e dans les variables d'environnement")
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    # Construire le prompt avec le profil
    prompt = _build_plan_prompt(metadata, study_context, writing_profile)
    
    # GÃ©nÃ©rer le plan
    response = model.generate_content(prompt)
    
    # Parser la rÃ©ponse
    plan_text = response.text.strip()
    
    # Nettoyer le JSON
    if "```json" in plan_text:
        plan_text = plan_text.split("```json")[1].split("```")[0].strip()
    elif "```" in plan_text:
        plan_text = plan_text.split("```")[1].split("```")[0].strip()
    
    # Parser le JSON
    plan = json.loads(plan_text)
    
    # Post-traitement selon le profil
    plan = _post_process_plan_for_profile(plan, writing_profile)
    
    return plan


def _build_plan_prompt(
    metadata: Dict[str, Any],
    study_context: Optional[Any] = None,
    writing_profile: Optional[Union[str, 'WritingProfile']] = None
) -> str:
    """Construit le prompt pour gÃ©nÃ©rer le plan selon le profil"""
    
    from datetime import datetime
    
    # Informations de base
    num_rows = metadata["shape"]["rows"]
    num_cols = metadata["shape"]["columns"]
    numeric_cols = metadata["numeric_columns"]
    categorical_cols = metadata["categorical_columns"]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DÃ‰TERMINER LE PROFIL ET SES INSTRUCTIONS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    profile_name = "standard"
    profile_instructions = ""
    
    if writing_profile:
        # Convertir en string si nÃ©cessaire
        if isinstance(writing_profile, WritingProfile):
            profile_name = writing_profile.value
        elif isinstance(writing_profile, str):
            profile_name = writing_profile.lower()
        
        # Instructions spÃ©cifiques par profil
        if profile_name == "academic":
            profile_instructions = """
PROFIL ACADÃ‰MIQUE - STRUCTURE ATTENDUE :

Le plan doit suivre les standards acadÃ©miques :

1. **Introduction et Cadre ThÃ©orique**
   - Revue de littÃ©rature pertinente
   - Question de recherche claire
   - HypothÃ¨ses Ã  tester
   - Objectifs de l'Ã©tude

2. **MÃ©thodologie**
   - Description des donnÃ©es
   - Approche analytique
   - Justification des mÃ©thodes statistiques
   - Limites mÃ©thodologiques

3. **RÃ©sultats**
   - Analyse descriptive dÃ©taillÃ©e
   - Tests d'hypothÃ¨ses
   - Analyses bivariÃ©es et multivariÃ©es
   - PrÃ©sentation rigoureuse des rÃ©sultats

4. **Discussion**
   - InterprÃ©tation des rÃ©sultats
   - Comparaison avec la littÃ©rature
   - Implications thÃ©oriques
   - Limites de l'Ã©tude

5. **Conclusion**
   - SynthÃ¨se des contributions
   - Perspectives de recherche future

STYLE : Formel, rigoureux, vocabulaire scientifique prÃ©cis
"""
        
        elif profile_name == "consultant":
            profile_instructions = """
PROFIL CONSULTANT - STRUCTURE ATTENDUE :

Le plan doit Ãªtre orientÃ© ACTION et BUSINESS :

1. **Executive Summary**
   - Contexte business et enjeux
   - 3-5 insights clÃ©s (bullet points)
   - Recommandations principales (top 3)
   - Impacts quantifiÃ©s

2. **Analyse Exploratoire et Diagnostic**
   - Ã‰tat des lieux (oÃ¹ en sommes-nous ?)
   - Identification des PROBLÃ‰MATIQUES business
   - DÃ©tection des OPPORTUNITÃ‰S
   - KPIs et mÃ©triques clÃ©s

3. **Analyse Approfondie**
   - Deep dive sur les leviers de performance
   - Segmentation et patterns business-critical
   - CorrÃ©lations et drivers identifiÃ©s
   - Benchmarks (si applicable)

4. **ModÃ©lisation et ScÃ©narios**
   - ModÃ¨les prÃ©dictifs pour la prise de dÃ©cision
   - ScÃ©narios d'optimisation
   - Quantification des impacts (â‚¬, %, ROI)
   - Analyse de sensibilitÃ©

5. **Recommandations StratÃ©giques et Plan d'Action** â­ CRITIQUE
   - SynthÃ¨se des insights clÃ©s
   - Recommandations actionnables (Court terme / Moyen terme)
   - Priorisation (Impact vs Effort)
   - Plan de mise en Å“uvre dÃ©taillÃ©
   - KPIs de suivi
   - Quick wins identifiÃ©s

STYLE : OrientÃ© action, focus rÃ©sultats, langage business, visuel
MOTS-CLÃ‰S Ã€ UTILISER : OpportunitÃ©s, Leviers, Optimisation, ROI, Impact, Recommandations, Actions prioritaires
"""
        
        elif profile_name == "institutional":
            profile_instructions = """
PROFIL INSTITUTIONNEL - STRUCTURE ATTENDUE :

Le plan doit garantir TRANSPARENCE et TRAÃ‡ABILITÃ‰ :

1. **Contexte et Cadre RÃ©glementaire**
   - Mission et mandat
   - Obligations lÃ©gales et rÃ©glementaires
   - Standards et normes applicables
   - Objectifs institutionnels

2. **MÃ©thodologie et Processus**
   - Collecte des donnÃ©es (traÃ§abilitÃ© complÃ¨te)
   - Validation et contrÃ´le qualitÃ©
   - MÃ©thodes d'analyse (justification)
   - ConformitÃ© aux standards

3. **Analyse et RÃ©sultats**
   - Analyse descriptive exhaustive
   - Indicateurs de suivi
   - RÃ©sultats dÃ©taillÃ©s et documentÃ©s
   - Tableaux de bord rÃ©glementaires

4. **Conclusions et ConformitÃ©**
   - SynthÃ¨se des rÃ©sultats
   - Respect des obligations
   - Recommandations (si applicable)
   - Suivi et accountability

5. **Annexes et Documentation**
   - MÃ©thodologie dÃ©taillÃ©e
   - Sources de donnÃ©es
   - Glossaire
   - RÃ©fÃ©rences rÃ©glementaires

STYLE : Formel, neutre, factuel, traÃ§able, documentÃ©
"""
    
    # Contexte d'Ã©tude si disponible
    context_section = ""
    if study_context and hasattr(study_context, 'to_prompt_context'):
        context_section = f"""
CONTEXTE DE L'Ã‰TUDE:
{study_context.to_prompt_context()}
"""
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CONSTRUIRE LE PROMPT COMPLET
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    prompt = f"""
Tu es un expert en analyse statistique et rÃ©daction de rapports.

PROFIL DE RÃ‰DACTION : {profile_name.upper()}

{profile_instructions}

DONNÃ‰ES Ã€ ANALYSER:
- Nombre de lignes: {num_rows:,}
- Nombre de colonnes: {num_cols}
- Variables numÃ©riques ({len(numeric_cols)}): {', '.join(numeric_cols[:10])}{"..." if len(numeric_cols) > 10 else ""}
- Variables catÃ©gorielles ({len(categorical_cols)}): {', '.join(categorical_cols[:10])}{"..." if len(categorical_cols) > 10 else ""}

{context_section}

TÃ‚CHE:
GÃ©nÃ¨re un plan de rapport statistique dÃ©taillÃ© ADAPTÃ‰ AU PROFIL {profile_name.upper()}.

FORMAT DE SORTIE (JSON):
{{
  "titre": "Titre du rapport (adaptÃ© au profil)",
  "date": "{datetime.now().strftime('%Y-%m-%d')}",
  "auteur": "AI Statistical Reporter",
  "profil": "{profile_name}",
  "chapitres": [
    {{
      "numero": "1",
      "titre": "Titre du chapitre 1",
      "sections": [
        {{
          "titre": "Titre de la section",
          "analyses": [
            "Analyse concrÃ¨te 1",
            "Analyse concrÃ¨te 2",
            "Analyse concrÃ¨te 3"
          ]
        }}
      ]
    }}
  ]
}}

RÃˆGLES CRITIQUES:
1. RESPECTE STRICTEMENT la structure du profil {profile_name.upper()}
2. Pour CONSULTANT : INCLURE OBLIGATOIREMENT un chapitre "Recommandations StratÃ©giques" en dernier
3. Adapte le vocabulaire au profil (acadÃ©mique = scientifique, consultant = business, institutionnel = formel)
4. CrÃ©e 4-6 chapitres pertinents selon le profil
5. Chaque chapitre a 2-4 sections
6. Chaque section a 3-5 analyses concrÃ¨tes et adaptÃ©es aux donnÃ©es
7. Retourne UNIQUEMENT le JSON, sans texte additionnel

GÃ©nÃ¨re maintenant le plan en JSON:
"""
    
    return prompt


def _post_process_plan_for_profile(
    plan: Dict[str, Any],
    writing_profile: Optional[Union[str, 'WritingProfile']] = None
) -> Dict[str, Any]:
    """
    Post-traite le plan pour s'assurer qu'il respecte le profil
    Ajoute des Ã©lÃ©ments manquants si nÃ©cessaire
    """
    
    if not writing_profile:
        return plan
    
    # Convertir en string
    if isinstance(writing_profile, WritingProfile):
        profile_name = writing_profile.value
    elif isinstance(writing_profile, str):
        profile_name = writing_profile.lower()
    else:
        return plan
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # POST-TRAITEMENT CONSULTANT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if profile_name == "consultant":
        # VÃ©rifier si un chapitre "Recommandations" existe
        has_recommendations = False
        has_executive_summary = False
        
        chapitres = plan.get('chapitres', [])
        
        for chap in chapitres:
            titre_lower = chap.get('titre', '').lower()
            if 'recommandation' in titre_lower or 'action' in titre_lower:
                has_recommendations = True
            if 'executive' in titre_lower or 'synthÃ¨se' in titre_lower and chap.get('numero') == "1":
                has_executive_summary = True
        
        # Ajouter Executive Summary si manquant
        if not has_executive_summary:
            executive_summary = {
                'numero': '0',
                'titre': 'Executive Summary',
                'sections': [
                    {
                        'titre': 'Contexte et enjeux business',
                        'analyses': [
                            'Contexte de l\'analyse',
                            'ProblÃ©matiques identifiÃ©es',
                            'Objectifs business'
                        ]
                    },
                    {
                        'titre': 'Insights clÃ©s',
                        'analyses': [
                            'Top 3-5 dÃ©couvertes majeures',
                            'OpportunitÃ©s dÃ©tectÃ©es',
                            'Risques identifiÃ©s'
                        ]
                    },
                    {
                        'titre': 'Recommandations principales',
                        'analyses': [
                            'Actions prioritaires (top 3)',
                            'Impacts attendus',
                            'Quick wins'
                        ]
                    }
                ]
            }
            plan['chapitres'].insert(0, executive_summary)
            
            # RenumÃ©roter les chapitres
            for i, chap in enumerate(plan['chapitres'], 1):
                chap['numero'] = str(i)
        
        # Ajouter chapitre Recommandations si manquant
        if not has_recommendations:
            recommendations_chapter = {
                'numero': str(len(plan['chapitres']) + 1),
                'titre': 'Recommandations StratÃ©giques et Plan d\'Action',
                'sections': [
                    {
                        'titre': 'SynthÃ¨se des insights business-critical',
                        'analyses': [
                            'RÃ©capitulatif des dÃ©couvertes majeures',
                            'HiÃ©rarchisation par impact business',
                            'OpportunitÃ©s vs Risques'
                        ]
                    },
                    {
                        'titre': 'Recommandations actionnables',
                        'analyses': [
                            'Actions court terme (0-3 mois) - Quick wins',
                            'Initiatives moyen terme (3-12 mois)',
                            'StratÃ©gies long terme (12+ mois)',
                            'Quantification des impacts (â‚¬, %, ROI)'
                        ]
                    },
                    {
                        'titre': 'Plan de mise en Å“uvre',
                        'analyses': [
                            'Roadmap et timeline',
                            'Ressources nÃ©cessaires',
                            'KPIs de suivi',
                            'Priorisation (Impact vs Effort)',
                            'Risques et mitigation'
                        ]
                    }
                ]
            }
            plan['chapitres'].append(recommendations_chapter)
    
    # Ajouter le profil au plan
    plan['profil'] = profile_name
    
    return plan


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E POUR TESTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python week2_architect_agent.py <csv_file_path> [profile]")
        print("Profiles: academic, consultant, institutional")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    profile = sys.argv[2] if len(sys.argv) > 2 else None
    
    print("[SEARCH] Analyse du fichier en cours...")
    metadata = analyze_csv(csv_path)
    
    print(f"\n[OK] Analyse terminÃ©e!")
    print(f"   - Fichier: {metadata['file_info']['filename']}")
    print(f"   - Encodage: {metadata['file_info']['encoding']}")
    print(f"   - Lignes: {metadata['shape']['rows']:,}")
    print(f"   - Colonnes: {metadata['shape']['columns']}")
    
    print(f"\nğŸ“ GÃ©nÃ©ration du plan (profil: {profile or 'standard'})...")
    plan = generate_report_plan(metadata, writing_profile=profile)
    
    print(f"\n[OK] Plan gÃ©nÃ©rÃ©!")
    print(f"   - Titre: {plan['titre']}")
    print(f"   - Profil: {plan.get('profil', 'N/A')}")
    print(f"   - Chapitres: {len(plan['chapitres'])}")
    
    # Afficher les titres des chapitres
    for i, chap in enumerate(plan['chapitres'], 1):
        print(f"      {i}. {chap['titre']}")
    
    # Sauvegarder le plan
    output_file = f"report_plan_{profile or 'standard'}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(plan, f, indent=2, ensure_ascii=False)
    
    print(f"\n[SAVE] Plan sauvegardÃ© dans {output_file}")