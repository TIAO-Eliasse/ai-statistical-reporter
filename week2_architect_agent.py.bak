"""
Week 2 - Architect Agent - VERSION RAG COMPL√àTE (CORRIG√âE INS)
Agent pour analyser les donn√©es CSV et g√©n√©rer un plan de rapport

üéØ NOUVEAUT√âS RAG :
‚úÖ M√©tadonn√©es ENRICHIES
‚úÖ Contraintes STRICTES anti-hallucination
‚úÖ VALIDATION automatique
‚úÖ Support profils writing_profiles.py
‚úÖ E2B corrig√©
‚≠ê PROFIL INSTITUTIONAL corrig√© ‚Üí Approche INS/Minist√®res (exploratoire)
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, Optional, Union
from datetime import datetime


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONFIGURATION E2B
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

E2B_CONFIG = {
    'timeout': 300,
    'keep_alive': True,
    'api_key': os.getenv('E2B_API_KEY'),
    'enabled': os.getenv('USE_E2B', 'false').lower() == 'true'
}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# IMPORT DES PROFILS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

try:
    from study_context import WritingProfile
    from writing_profiles import get_writing_style_block, get_profile_summary
    PROFILES_AVAILABLE = True
except ImportError:
    PROFILES_AVAILABLE = False
    class WritingProfile:
        ACADEMIC = "academic"
        CONSULTANT = "consultant"
        INSTITUTIONAL = "institutional"


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# IMPORT RAG VALIDATOR
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

try:
    from rag_validator import validate_plan_against_metadata, print_validation_report
    RAG_VALIDATOR_AVAILABLE = True
except ImportError:
    RAG_VALIDATOR_AVAILABLE = False
    print("‚ö†Ô∏è rag_validator non disponible - validation d√©sactiv√©e")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ANALYSE CSV ENRICHIE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def analyze_csv(csv_path: str) -> Dict[str, Any]:
    """Analyse ENRICHIE d'un fichier CSV/Excel avec RAG"""
    
    use_e2b = E2B_CONFIG['enabled'] and E2B_CONFIG['api_key']
    
    if use_e2b:
        try:
            from e2b_code_interpreter import Sandbox
            print("‚ÑπÔ∏è E2B activ√©")
            return _analyze_csv_with_e2b_robust(csv_path)
        except Exception as e:
            print(f"‚ö†Ô∏è E2B error, fallback: {e}")
            return _analyze_csv_locally_enriched(csv_path)
    else:
        print("‚ÑπÔ∏è Analyse locale")
        return _analyze_csv_locally_enriched(csv_path)


def _analyze_csv_locally_enriched(csv_path: str) -> Dict[str, Any]:
    """Version ENRICHIE pour RAG - Analyse d√©taill√©e par colonne"""
    import pandas as pd
    import numpy as np
    
    file_path = Path(csv_path)
    file_extension = file_path.suffix.lower()
    
    # Chargement multi-encodage
    if file_extension == '.csv':
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252', 'cp1252']
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                encoding_used = encoding
                break
            except (UnicodeDecodeError, Exception):
                continue
        else:
            raise ValueError("Impossible de d√©tecter l'encodage")
    
    elif file_extension in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path, engine='openpyxl' if file_extension == '.xlsx' else None)
        encoding_used = 'excel'
    
    else:
        raise ValueError(f"Format non support√© : {file_extension}")
    
    # Analyse enrichie colonne par colonne
    columns_info = []
    
    for col in df.columns:
        col_info = {
            'name': col,
            'dtype': str(df[col].dtype),
            'nunique': int(df[col].nunique()),
            'missing': int(df[col].isnull().sum()),
            'missing_pct': float(df[col].isnull().sum() / len(df) * 100) if len(df) > 0 else 0
        }
        
        if pd.api.types.is_numeric_dtype(df[col]):
            col_info['is_numeric'] = True
            col_info['is_categorical'] = False
            
            col_data = df[col].dropna()
            if len(col_data) > 0:
                col_info['min'] = float(col_data.min())
                col_info['max'] = float(col_data.max())
                col_info['mean'] = float(col_data.mean())
                col_info['median'] = float(col_data.median())
                col_info['std'] = float(col_data.std())
                col_info['q25'] = float(col_data.quantile(0.25))
                col_info['q75'] = float(col_data.quantile(0.75))
                col_info['is_encoded'] = col_info['nunique'] < 10
                
                if col_info['is_encoded']:
                    value_counts = df[col].value_counts().sort_index()
                    col_info['distribution'] = {str(k): int(v) for k, v in value_counts.items()}
        else:
            col_info['is_numeric'] = False
            col_info['is_categorical'] = True
            col_info['is_encoded'] = False
            
            if col_info['nunique'] < 1000:
                value_counts = df[col].value_counts().head(10)
                col_info['top_values'] = {str(k): int(v) for k, v in value_counts.items()}
                col_info['top_values_pct'] = {
                    str(k): round(float(v / len(df) * 100), 2)
                    for k, v in value_counts.items()
                }
        
        columns_info.append(col_info)
    
    # M√©tadonn√©es compl√®tes
    metadata = {
        "file_info": {
            "filename": file_path.name,
            "extension": file_extension,
            "encoding": encoding_used,
            "size_mb": round(os.path.getsize(csv_path) / (1024 * 1024), 2)
        },
        "shape": {
            "rows": int(len(df)),
            "columns": int(len(df.columns))
        },
        "columns": columns_info,
        "numeric_columns": [c['name'] for c in columns_info if c.get('is_numeric')],
        "categorical_columns": [c['name'] for c in columns_info if c.get('is_categorical')],
        "encoded_columns": [c['name'] for c in columns_info if c.get('is_encoded')],
        "columns_with_missing": [c['name'] for c in columns_info if c['missing'] > 0],
        "sample_data": df.head(3).to_dict('records'),
        "columns_names": list(df.columns),
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "missing_values": {
            col: {"count": c['missing'], "percentage": c['missing_pct']}
            for c in columns_info
        },
        "basic_stats": {}
    }
    
    for col in metadata["numeric_columns"]:
        col_data = next(c for c in columns_info if c['name'] == col)
        if 'mean' in col_data:
            metadata["basic_stats"][col] = {
                "count": len(df[col].dropna()),
                "mean": col_data['mean'],
                "median": col_data['median'],
                "std": col_data['std'],
                "min": col_data['min'],
                "max": col_data['max'],
                "q25": col_data['q25'],
                "q75": col_data['q75']
            }
    
    for col in metadata["categorical_columns"]:
        col_data = next(c for c in columns_info if c['name'] == col)
        metadata["basic_stats"][col] = {
            "unique_count": col_data['nunique'],
            "most_common": col_data.get('top_values', {})
        }
    
    return metadata


def _analyze_csv_with_e2b_robust(csv_path: str) -> Dict[str, Any]:
    """Version E2B robuste"""
    from e2b_code_interpreter import Sandbox
    
    sandbox = None
    
    try:
        sandbox = Sandbox(
            api_key=E2B_CONFIG['api_key'],
            timeout=E2B_CONFIG['timeout'],
            keep_alive=E2B_CONFIG['keep_alive']
        )
        
        print(f"‚úÖ Sandbox cr√©√©e : {sandbox.sandbox_id}")
        result = _analyze_csv_locally_enriched(csv_path)
        return result
    
    except Exception as e:
        print(f"‚ùå E2B error : {str(e)[:200]}")
        raise
    
    finally:
        if sandbox:
            try:
                sandbox.close()
                print(f"‚úÖ Sandbox ferm√©e")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur fermeture : {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# G√âN√âRATION DU PLAN AVEC RAG
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def generate_report_plan(
    metadata: Dict[str, Any],
    study_context: Optional[Any] = None,
    writing_profile: Optional[Union[str, 'WritingProfile']] = None,
    max_attempts: int = 3
) -> Dict[str, Any]:
    """G√©n√®re plan avec VALIDATION RAG automatique"""
    import google.generativeai as genai
    
    api_key = os.getenv("GMINI_API_KEY")
    if not api_key:
        raise ValueError("GMINI_API_KEY non trouv√©e")
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.0-flash-exp")
    
    for attempt in range(1, max_attempts + 1):
        try:
            print(f"‚è≥ G√©n√©ration plan (tentative {attempt}/{max_attempts})...")
            
            prompt = _build_dynamic_prompt_with_rag(metadata, study_context, writing_profile)
            response = model.generate_content(prompt)
            plan_text = response.text.strip()
            
            if "```json" in plan_text:
                plan_text = plan_text.split("```json")[1].split("```")[0].strip()
            elif "```" in plan_text:
                plan_text = plan_text.split("```")[1].split("```")[0].strip()
            
            plan = json.loads(plan_text)
            
            # Validation RAG
            if RAG_VALIDATOR_AVAILABLE:
                plan, validation_report = validate_plan_against_metadata(plan, metadata)
                print_validation_report(validation_report)
                
                if validation_report['is_valid']:
                    print("‚úÖ Plan valid√© et accept√©")
                    break
                elif attempt == max_attempts:
                    print(f"‚ö†Ô∏è Plan accept√© malgr√© {validation_report['hallucinations_count']} hallucination(s)")
                    break
                else:
                    print(f"‚ùå {validation_report['hallucinations_count']} hallucination(s), r√©g√©n√©ration...")
                    continue
            else:
                break
        
        except Exception as e:
            print(f"‚ùå Erreur : {e}")
            if attempt == max_attempts:
                print("‚ùå √âchec, plan fallback")
                return _generate_fallback_plan(metadata, writing_profile)
            continue
    
    plan = _post_process_plan_for_profile(plan, writing_profile, metadata)
    
    return plan


def _build_dynamic_prompt_with_rag(
    metadata: Dict[str, Any],
    study_context: Optional[Any] = None,
    writing_profile: Optional[Union[str, 'WritingProfile']] = None
) -> str:
    """Construit prompt DYNAMIQUE avec contraintes RAG strictes"""
    
    profile_name = "academic"
    profile_enum = None
    
    if writing_profile:
        if isinstance(writing_profile, WritingProfile):
            profile_name = writing_profile.value
            profile_enum = writing_profile
        elif isinstance(writing_profile, str):
            profile_name = writing_profile.lower()
            if PROFILES_AVAILABLE:
                profile_map = {
                    'academic': WritingProfile.ACADEMIC,
                    'consultant': WritingProfile.CONSULTANT,
                    'institutional': WritingProfile.INSTITUTIONAL
                }
                profile_enum = profile_map.get(profile_name)
    
    columns = metadata.get('columns', [])
    num_rows = metadata['shape']['rows']
    num_cols = metadata['shape']['columns']
    
    prompt = f"""
Tu es un statisticien expert en analyse de donn√©es et r√©daction de rapports.

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë DONN√âES √Ä ANALYSER                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìä VOLUME :
- Lignes : {num_rows:,}
- Colonnes : {num_cols}

üìã COLONNES DISPONIBLES (LISTE EXHAUSTIVE) :

"""
    
    if metadata.get('numeric_columns'):
        prompt += f"üî¢ Variables num√©riques ({len(metadata['numeric_columns'])}) :\n"
        for col_name in metadata['numeric_columns'][:20]:
            col = next((c for c in columns if c['name'] == col_name), None)
            if col:
                if col.get('is_encoded'):
                    prompt += f"  ‚Ä¢ {col_name} [ENCOD√âE - {col['nunique']} cat√©gories]\n"
                elif 'mean' in col:
                    prompt += f"  ‚Ä¢ {col_name} (min: {col['min']:.2f}, max: {col['max']:.2f}, moy: {col['mean']:.2f})\n"
    
    if metadata.get('categorical_columns'):
        prompt += f"\nüìã Variables cat√©gorielles ({len(metadata['categorical_columns'])}) :\n"
        for col_name in metadata['categorical_columns'][:20]:
            col = next((c for c in columns if c['name'] == col_name), None)
            if col:
                top = list(col.get('top_values', {}).keys())[:3]
                prompt += f"  ‚Ä¢ {col_name} ({col['nunique']} cat√©gories, top: {', '.join(top)})\n"
    
    if metadata.get('encoded_columns'):
        prompt += f"\n‚ö†Ô∏è Variables ENCOD√âES : {', '.join(metadata['encoded_columns'][:15])}\n"
    
    if metadata.get('columns_with_missing'):
        prompt += f"\n‚ö†Ô∏è Valeurs manquantes : {', '.join(metadata['columns_with_missing'][:15])}\n"
    
    if study_context and hasattr(study_context, 'to_prompt_context'):
        prompt += f"""

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë CONTEXTE DE L'√âTUDE                                                         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

{study_context.to_prompt_context()}
"""
    
    if PROFILES_AVAILABLE and profile_enum:
        style_block = get_writing_style_block(profile_enum)
        prompt += f"\n{style_block}\n"
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CONTRAINTES RAG ANTI-HALLUCINATION
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    prompt += f"""

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë üî¥ R√àGLES ANTI-HALLUCINATION (ULTRA-CRITIQUE)                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

COLONNES DISPONIBLES (LISTE COMPL√àTE) :

üî¢ Num√©riques : {', '.join(metadata['numeric_columns'])}

üìã Cat√©gorielles : {', '.join(metadata['categorical_columns'])}

üî¥ R√àGLES ABSOLUES :

1. ‚úÖ Utilise UNIQUEMENT les colonnes list√©es ci-dessus
2. ‚ùå N'invente AUCUNE nouvelle colonne (satisfaction, NPS, conversion, r√©tention)
3. ‚ùå N'invente AUCUNE statistique
4. ‚ö†Ô∏è Si analyse n√©cessite colonne absente ‚Üí SAUTE
5. ‚ö†Ô∏è V√©rifie 3 FOIS avant de mentionner une colonne

‚ùå EXEMPLES HALLUCINATIONS √Ä √âVITER :

- ‚ùå "Analyse satisfaction client" (si pas de colonne "satisfaction")
- ‚ùå "Distribution NPS" (si pas de colonne "NPS")
- ‚ùå "Taux conversion" (si pas de colonne "conversion")
- ‚ùå "Corr√©lation satisfaction √ó r√©tention" (si colonnes absentes)

‚úÖ EXEMPLES CORRECTS :

- ‚úÖ "Distribution {metadata['numeric_columns'][0] if metadata.get('numeric_columns') else 'variable'}"
- ‚úÖ "R√©partition {metadata['categorical_columns'][0] if metadata.get('categorical_columns') else 'cat√©gorie'}"
- ‚úÖ "Corr√©lation {metadata['numeric_columns'][0] if len(metadata.get('numeric_columns', [])) > 0 else 'X'} √ó {metadata['numeric_columns'][1] if len(metadata.get('numeric_columns', [])) > 1 else 'Y'}"

üî¥ P√âNALIT√â : Hallucination = Plan REJET√â et r√©g√©n√©ration

Tu as {len(metadata['numeric_columns']) + len(metadata['categorical_columns'])} colonnes.
C'est SUFFISANT. N'en invente AUCUNE autre !

"""
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ‚≠ê INSTRUCTIONS PROFIL SP√âCIFIQUES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    prompt += """

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë R√àGLES STRUCTURELLES PAR PROFIL                                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

"""
    
    if profile_name == "academic":
        prompt += """
üéì PROFIL ACAD√âMIQUE (Recherche universitaire) :

STRUCTURE OBLIGATOIRE : IMRAD (Introduction, Methods, Results, Discussion)

1. **Introduction et Cadre Th√©orique**
   - Contexte de recherche
   - Revue de litt√©rature
   - ‚≠ê Hypoth√®ses de d√©part (H1, H2, H3)
   - Question de recherche
   - Objectifs

2. **M√©thodologie (Methods)**
   - Description donn√©es et collecte
   - ‚≠ê Justification th√©orique des tests statistiques
   - Outils d'analyse (avec pourquoi : tests de Pearson car...)
   - Traitement valeurs manquantes
   - ‚≠ê Limites m√©thodologiques anticip√©es

3. **R√©sultats (Results)** - FAITS UNIQUEMENT
   - Statistiques descriptives par variable
   - Tests d'hypoth√®ses (p-values)
   - Corr√©lations
   - ‚ö†Ô∏è PAS d'interpr√©tation ici

4. **Discussion** ‚≠ê OBLIGATOIRE
   - Interpr√©tation des r√©sultats
   - Lien avec litt√©rature
   - ‚≠ê Limites de l'√©tude
   - Implications th√©oriques

5. **Conclusion**
   - Synth√®se
   - ‚≠ê Perspectives recherche futures
   - Ouvertures

"""
    
    elif profile_name == "consultant":
        prompt += """
üíº PROFIL CONSULTANT (D√©cision business) :

STRUCTURE OBLIGATOIRE : Executive Summary + Analyses + Recommandations

1. **Executive Summary** ‚≠ê EN PREMIER (OBLIGATOIRE)
   
   1.1. Contexte business
   1.2. ‚≠ê Insights cl√©s (3-5)
        Format : "üí° [CHIFFRE] ‚Üí [IMPLICATION BUSINESS]"
   1.3. ‚≠ê Top 3 recommandations
   1.4. Impacts quantifi√©s (ROI, ‚Ç¨, %)

2-4. **Analyses interm√©diaires**
   - Focus Top/Bottom performers
   - Segmentation actionnable
   - KPIs cl√©s

5. **Recommandations Strat√©giques** ‚≠ê EN DERNIER (OBLIGATOIRE)
   
   5.1. Synth√®se insights
   
   5.2. ‚≠ê Priorisation Impact √ó Effort
        Matrice 2√ó2 :
        - üü¢ QUICK WINS (High Impact / Low Effort)
        - üü° Projets strat√©giques (High Impact / High Effort)
        - ‚ö™ Low priority
   
   5.3. ‚≠ê Plan mise en ≈ìuvre
        - Court terme (0-3 mois)
        - Moyen terme (3-12 mois)
   
   5.4. ‚≠ê KPIs de suivi par recommandation

"""
    
    elif profile_name == "institutional":
        # ‚úÖ G√©n√©rer exemples DYNAMIQUES bas√©s sur vraies colonnes
        example_numeric = metadata['numeric_columns'][0] if metadata.get('numeric_columns') else 'Indicateur_A'
        example_numeric_2 = metadata['numeric_columns'][1] if len(metadata.get('numeric_columns', [])) > 1 else 'Indicateur_B'
        example_categorical = metadata['categorical_columns'][0] if metadata.get('categorical_columns') else 'Variable_X'
        
        # D√©tecter th√©matique donn√©es (entreprises, m√©nages, √©tudiants, etc.)
        data_theme = "unit√©s observ√©es"
        all_cols_text = ' '.join([c.lower() for c in metadata.get('columns_names', [])])
        if 'entreprise' in all_cols_text or 'promoteur' in all_cols_text or 'ca' in all_cols_text:
            data_theme = "entreprises"
        elif 'm√©nage' in all_cols_text or 'famille' in all_cols_text:
            data_theme = "m√©nages"
        elif '√©tudiant' in all_cols_text or '√©l√®ve' in all_cols_text:
            data_theme = "√©tudiants"
        elif 'patient' in all_cols_text or 'sant√©' in all_cols_text:
            data_theme = "patients"
        
        prompt += f"""
üèõÔ∏è PROFIL INSTITUTIONAL (INS / Minist√®res / Rapports statistiques officiels) :

‚≠ê APPROCHE : Analyse EXPLORATOIRE statistique √† haut niveau
Focus : INDICATEURS + INSIGHTS + Exploration progressive

üìä VOS DONN√âES : {num_rows:,} {data_theme}, {len(metadata['numeric_columns'])} indicateurs num√©riques, {len(metadata['categorical_columns'])} variables cat√©gorielles

STRUCTURE RECOMMAND√âE (‚ö†Ô∏è ADAPTER LES TITRES √Ä VOS DONN√âES) :

1. **Contexte et Objectifs** (exemple de titre adapt√© √† vos donn√©es)
   
   ‚úÖ BON : "Contexte de l'analyse des {data_theme}"
   ‚úÖ BON : "Objectifs de l'√©tude sur les {data_theme}"
   ‚ùå MAUVAIS : "Cadre r√©glementaire" (trop administratif)

2. **Pr√©sentation Donn√©es et Indicateurs** (titre adaptatif)
   
   ‚úÖ BON : "Pr√©sentation des {num_rows:,} {data_theme} et {len(metadata['numeric_columns']) + len(metadata['categorical_columns'])} indicateurs"
   ‚úÖ BON : "Vue d'ensemble des donn√©es collect√©es"
   
   Contenu :
   - Volume : {num_rows:,} {data_theme} observ√©es
   - Indicateurs cl√©s disponibles
   - Qualit√© et compl√©tude

3. **Analyse UNIVARI√âE** ‚≠ê OBLIGATOIRE (titres avec VRAIS noms colonnes)
   
   ‚úÖ EXEMPLES ADAPT√âS √Ä VOS DONN√âES :
   
   Section : "Analyse de l'indicateur {example_numeric}"
   Analyses :
   - "Distribution de {example_numeric}"
   - "Statistiques descriptives : moyenne, m√©diane, dispersion"
   - "Identification des valeurs atypiques"
   
   Section : "R√©partition par {example_categorical}"
   Analyses :
   - "Effectifs et proportions par modalit√© de {example_categorical}"
   - "Modalit√©s dominantes"
   
   ‚ö†Ô∏è Cr√©er UNE section par indicateur cl√© (au moins top 5-10)

4. **Analyse BIVARI√âE** ‚≠ê OBLIGATOIRE (relations entre VRAIES variables)
   
   ‚úÖ EXEMPLES ADAPT√âS √Ä VOS DONN√âES :
   
   Section : "Relations entre {example_numeric} et {example_numeric_2}"
   Analyses :
   - "Corr√©lation entre {example_numeric} et {example_numeric_2}"
   - "Analyse de la relation"
   
   Section : "Analyse crois√©e : {example_categorical} √ó indicateurs"
   Analyses :
   - "Comparaison des indicateurs selon {example_categorical}"
   - "Disparit√©s entre modalit√©s"
   
   ‚ö†Ô∏è Utiliser NOMS EXACTS des colonnes

5. **Analyse MULTIVARI√âE** (si >3 variables, optionnel)
   
   ‚úÖ EXEMPLES :
   - "Segmentation des {data_theme} : profils types"
   - "Facteurs explicatifs de [indicateur cible]"
   - "Vue synth√©tique multi-indicateurs"

6. **Synth√®se des INSIGHTS** ‚≠ê OBLIGATOIRE
   
   ‚úÖ BON : "Synth√®se des observations statistiques sur les {data_theme}"
   ‚úÖ BON : "Faits marquants et tendances identifi√©es"
   
   Contenu :
   - üìä Faits marquants par indicateur
   - üìä Tendances principales observ√©es
   - ‚ö†Ô∏è Disparit√©s et h√©t√©rog√©n√©it√©s
   - ‚ö†Ô∏è Points d'attention m√©thodologiques

üéØ R√àGLES TITRES INSTITUTIONAL :

‚úÖ TITRES ADAPTATIFS (s'adapter aux donn√©es) :
- Utiliser NOMS R√âELS colonnes : "{example_numeric}", "{example_categorical}"
- Utiliser th√©matique donn√©es : "{data_theme}"
- √ätre SP√âCIFIQUE : "Distribution {example_numeric}" pas "Distribution variable"

‚ùå TITRES G√âN√âRIQUES (√† √©viter) :
- "Analyse univari√©e" ‚Üí trop vague
- "Variable X" ‚Üí utiliser vrai nom
- "Indicateur 1" ‚Üí utiliser vrai nom

üìù STYLE R√âDACTION :

‚úÖ √Ä FAIRE :
- Vocabulaire accessible : "r√©partition", "proportion", "effectif"
- Observations factuelles : "Les donn√©es r√©v√®lent que..."
- Focus INDICATEURS et INSIGHTS
- Progression : univari√© ‚Üí bivari√© ‚Üí multivari√©

‚ùå √Ä √âVITER :
- Recommandations : "Il faut...", "Nous recommandons..."
- Jargon : "h√©t√©rosc√©dasticit√©", "kurtosis"
- Interpr√©tations subjectives
"""
    
    # Format JSON
    prompt += f"""

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë FORMAT JSON REQUIS                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

{{
  "titre": "Titre adapt√© aux donn√©es",
  "date": "{datetime.now().strftime('%Y-%m-%d')}",
  "auteur": "AI Statistical Reporter",
  "profil": "{profile_name}",
  "chapitres": [
    {{
      "numero": "1",
      "titre": "Titre avec NOM COLONNE r√©elle",
      "sections": [
        {{
          "titre": "Section SP√âCIFIQUE (colonne r√©elle)",
          "analyses": ["Analyse avec NOM VARIABLE r√©el"]
        }}
      ]
    }}
  ]
}}

‚ö†Ô∏è RAPPELS :
1. Utilise NOMS EXACTS colonnes
2. N'invente RIEN
3. Adapte structure au profil {profile_name.upper()}

üöÄ G√âN√àRE LE PLAN JSON.
"""
    
    return prompt


def _post_process_plan_for_profile(
    plan: Dict[str, Any],
    writing_profile: Optional[Union[str, 'WritingProfile']],
    metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """Post-traitement selon profil"""
    
    profile_name = "academic"
    if writing_profile:
        if isinstance(writing_profile, WritingProfile):
            profile_name = writing_profile.value
        elif isinstance(writing_profile, str):
            profile_name = writing_profile.lower()
    
    plan['profil'] = profile_name
    
    # Academic : Discussion (titre adaptatif)
    if profile_name == "academic":
        titles = [c['titre'].lower() for c in plan.get('chapitres', [])]
        if not any('discussion' in t for t in titles):
            # D√©tecter th√©matique pour titre adaptatif
            data_theme_subject = "r√©sultats"
            if any('entreprise' in str(metadata.get('columns_names', [])).lower()):
                data_theme_subject = "entreprises √©tudi√©es"
            elif any('m√©nage' in str(metadata.get('columns_names', [])).lower()):
                data_theme_subject = "m√©nages analys√©s"
            
            plan['chapitres'].append({
                'numero': str(len(plan['chapitres']) + 1),
                'titre': f'Discussion et Limites de l\'√âtude',
                'sections': [{
                    'titre': f'Interpr√©tation des {data_theme_subject}',
                    'analyses': [
                        'Interpr√©tation des r√©sultats au regard de la litt√©rature', 
                        'Limites m√©thodologiques de l\'√©tude', 
                        'Perspectives de recherche futures'
                    ]
                }]
            })
    
    # Consultant : Exec Summary + Recommandations
    elif profile_name == "consultant":
        first = plan['chapitres'][0] if plan.get('chapitres') else None
        if not first or 'executive' not in first['titre'].lower():
            plan['chapitres'].insert(0, {
                'numero': '1',
                'titre': 'Executive Summary',
                'sections': [{
                    'titre': 'Insights cl√©s et recommandations',
                    'analyses': ['üí° Insights majeurs', 'üéØ Top 3 recommandations', 'üí∞ Impacts quantifi√©s']
                }]
            })
        
        last = plan['chapitres'][-1]
        if 'recommandation' not in last['titre'].lower():
            plan['chapitres'].append({
                'numero': str(len(plan['chapitres']) + 1),
                'titre': 'Recommandations Strat√©giques',
                'sections': [
                    {'titre': 'Priorisation Impact √ó Effort', 'analyses': ['üü¢ Quick wins', 'üü° Projets strat√©giques']},
                    {'titre': 'Plan de mise en ≈ìuvre', 'analyses': ['Court terme (0-3 mois)', 'Moyen terme (3-12 mois)']},
                    {'titre': 'KPIs de suivi', 'analyses': ['Indicateurs de performance']}
                ]
            })
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ‚≠ê INSTITUTIONAL : Approche INS/Minist√®res CORRIG√âE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    elif profile_name == "institutional":
        # ‚úÖ NE PAS FIGER LES TITRES - V√©rifier juste structure
        titles = [c['titre'].lower() for c in plan.get('chapitres', [])]
        
        # V√©rifier pr√©sence structure exploratoire (sans forcer titres exacts)
        has_univariate = any(
            'univar' in t or 'indicateur' in t or 'descriptive' in t or 'exploration' in t 
            for t in titles
        )
        has_bivariate = any(
            'bivar' in t or 'crois√©' in t or 'relation' in t or 'corr√©lation' in t
            for t in titles
        )
        has_insights = any(
            'insight' in t or 'synth√®se' in t or 'conclusion' in t or 'marquant' in t
            for t in titles
        )
        
        # ‚ö†Ô∏è SEULEMENT ajouter chapitres MANQUANTS (pas tout reconstruire)
        
        # Si manque univari√©e, ajouter APR√àS intro
        if not has_univariate and len(plan.get('chapitres', [])) >= 2:
            # Ins√©rer apr√®s les 2 premiers chapitres (contexte + donn√©es)
            insert_pos = 2
            plan['chapitres'].insert(insert_pos, {
                'numero': str(insert_pos + 1),
                'titre': f'Analyse Exploratoire des {len(metadata["numeric_columns"]) + len(metadata["categorical_columns"])} Indicateurs',
                'sections': [
                    {
                        'titre': f'Distributions et statistiques descriptives',
                        'analyses': [
                            f'Analyses univari√©es de chaque indicateur',
                            'Tendances centrales et dispersions',
                            'Identification des valeurs atypiques'
                        ]
                    }
                ]
            })
        
        # Si manque bivari√©e, ajouter AVANT synth√®se
        if not has_bivariate and len(plan.get('chapitres', [])) >= 3:
            # Ins√©rer avant dernier chapitre
            insert_pos = len(plan['chapitres']) - 1
            plan['chapitres'].insert(insert_pos, {
                'numero': str(insert_pos + 1),
                'titre': 'Relations entre Indicateurs',
                'sections': [
                    {
                        'titre': 'Corr√©lations et croisements statistiques',
                        'analyses': [
                            'Corr√©lations entre variables num√©riques',
                            'Croisements variables cat√©gorielles √ó num√©riques',
                            'Identification relations significatives'
                        ]
                    }
                ]
            })
        
        # Si manque synth√®se, ajouter EN FIN
        if not has_insights:
            plan['chapitres'].append({
                'numero': str(len(plan['chapitres']) + 1),
                'titre': 'Synth√®se des Observations Statistiques',
                'sections': [{
                    'titre': 'Faits marquants et tendances',
                    'analyses': [
                        'Principales observations statistiques',
                        'Disparit√©s et h√©t√©rog√©n√©it√©s identifi√©es',
                        'Points d\'attention m√©thodologiques'
                    ]
                }]
            })
    
    # Renum√©roter
    for i, chap in enumerate(plan.get('chapitres', []), 1):
        chap['numero'] = str(i)
    
    return plan


def _generate_fallback_plan(
    metadata: Dict[str, Any],
    writing_profile: Optional[Union[str, 'WritingProfile']]
) -> Dict[str, Any]:
    """Plan de secours"""
    
    profile_name = "academic"
    if writing_profile:
        if isinstance(writing_profile, WritingProfile):
            profile_name = writing_profile.value
        elif isinstance(writing_profile, str):
            profile_name = writing_profile.lower()
    
    return {
        "titre": "Rapport Statistique",
        "date": datetime.now().strftime("%Y-%m-%d"),
        "auteur": "AI Statistical Reporter",
        "profil": profile_name,
        "chapitres": [
            {"numero": "1", "titre": "Introduction", "sections": [{"titre": "Contexte", "analyses": [f"{metadata['shape']['rows']:,} observations"]}]},
            {"numero": "2", "titre": "M√©thodologie", "sections": [{"titre": "Outils", "analyses": ["Statistiques descriptives"]}]},
            {"numero": "3", "titre": "Analyse", "sections": [{"titre": "R√©sultats", "analyses": ["Analyse descriptive"]}]},
            {"numero": "4", "titre": "Conclusions", "sections": [{"titre": "Synth√®se", "analyses": ["R√©sum√©"]}]}
        ]
    }


if __name__ == "__main__":
    """Tests"""
    
    print("="*70)
    print("TEST - WEEK2 RAG (VERSION INS CORRIG√âE)")
    print("="*70)
    
    print("\n‚úÖ RAG Features:")
    print("  - M√©tadonn√©es enrichies")
    print("  - Contraintes anti-hallucination")
    print(f"  - Validation : {RAG_VALIDATOR_AVAILABLE}")
    print(f"  - Profils : {PROFILES_AVAILABLE}")
    print("  ‚≠ê INSTITUTIONAL = Approche INS/Minist√®res (exploratoire)")
    
    try:
        import pandas as pd
        test_data = {
            'Age': [25, 30, 35],
            'CA_2015': [10000, 25000, 50000],
            'Region': ['LITTORAL', 'CENTRE', 'LITTORAL']
        }
        df = pd.DataFrame(test_data)
        df.to_csv('test.csv', index=False)
        
        metadata = analyze_csv('test.csv')
        print(f"\n‚úÖ Analyse: {len(metadata['columns'])} colonnes")
    
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
    
    print("\n" + "="*70)